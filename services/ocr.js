// åŸºç¡€ OCR æœåŠ¡ç±»
class BaseOCRService {
    constructor(config) {
        if (new.target === BaseOCRService) {
            throw new Error('BaseOCRService ä¸èƒ½ç›´æ¥å®ä¾‹åŒ–');
        }
        this.config = config;
    }

    async recognize(base64Image) {
        console.log(`ğŸ” å¼€å§‹${this.getDisplayName()}å¤„ç†...`);
        console.time('OCRå¤„ç†');

        try {
            const compressedImage = await this._compressImage(base64Image);
            const result = await this._performRecognition(compressedImage);
            
            if (!result) {
                console.log('âš ï¸ æœªæ£€æµ‹åˆ°æ–‡å­—');
                return '';
            }

            const processedText = this._processText(result);
            console.log('âœ… OCRå®Œæˆ:', processedText);
            return processedText;
        } catch (error) {
            console.error(`âŒ ${this.getDisplayName()}é”™è¯¯:`, error);
            throw error;
        } finally {
            console.timeEnd('OCRå¤„ç†');
        }
    }

    getDisplayName() {
        return 'æ–‡å­—è¯†åˆ«';
    }

    async _compressImage(base64Image) {
        return new Promise((resolve) => {
            const img = new Image();
            img.onload = () => {
                const canvas = document.createElement('canvas');
                const maxSize = this.config.MAX_IMAGE_SIZE || 1600;
                let { width, height } = img;

                if (width > height && width > maxSize) {
                    height = Math.floor((height * maxSize) / width);
                    width = maxSize;
                } else if (height > maxSize) {
                    width = Math.floor((width * maxSize) / height);
                    height = maxSize;
                }

                canvas.width = width;
                canvas.height = height;
                const ctx = canvas.getContext('2d');
                ctx.drawImage(img, 0, 0, width, height);
                
                resolve(canvas.toDataURL('image/jpeg', this.config.IMAGE_QUALITY || 0.95));
            };
            img.src = base64Image;
        });
    }

    async _performRecognition(image) {
        throw new Error('_performRecognition æ–¹æ³•å¿…é¡»ç”±å­ç±»å®ç°');
    }

    _processText(text) {
        if (!text) return text;
        
        text = text.replace(/\s+/g, ' ').replace(/\n+/g, '\n').trim();
        text = this._removeNoise(text);
        text = this._fixCommonErrors(text);
        text = this._extractMainContent(text);
        
        return text;
    }

    _removeNoise(text) {
        return text
            .replace(/[^\u4e00-\u9fa5a-zA-Z0-9.,?!;:'"()\[\]{}<>\/\\\s\-_+=@#$%^&*|~`]/g, '')
            .replace(/([.,?!;:'"()\[\]{}<>\/\\\-_+=@#$%^&*|~`])\1+/g, '$1');
    }

    _fixCommonErrors(text) {
        const corrections = {
            'æ›°': 'æ—¥', 'å·±': 'å·²', 'æœ«': 'æœª', 'è±¡': 'åƒ', 'å°ˆ': 'ä¸“',
            'è»Š': 'è½¦', 'å‚³': 'ä¼ ', 'æ±': 'ä¸œ', 'é¦¬': 'é©¬', 'å€‹': 'ä¸ª'
        };
        
        return Object.entries(corrections).reduce(
            (text, [error, correction]) => text.replace(new RegExp(error, 'g'), correction),
            text
        );
    }

    _extractMainContent(text) {
        const questionPatterns = [
            /[?ï¼Ÿ]/,
            /^(what|how|why|when|where|which|who|whose|whom|æ˜¯ä»€ä¹ˆ|å¦‚ä½•|ä¸ºä»€ä¹ˆ|ä»€ä¹ˆæ—¶å€™|åœ¨å“ªé‡Œ|å“ªä¸€ä¸ª|è°|è°çš„|è¯·é—®|è§£é‡Š|è®¡ç®—|æ±‚|è¯æ˜|åˆ†æ|æ¯”è¾ƒ|è¯„ä»·|è®¨è®º|åˆ—ä¸¾|æ¦‚è¿°|æ€»ç»“)/i
        ];

        if (questionPatterns.some(pattern => pattern.test(text))) {
            const sentences = text.split(/[.ã€‚!ï¼?ï¼Ÿ]/g).filter(s => s.trim());
            const questionSentences = sentences.filter(s => /[?ï¼Ÿ]/.test(s));
            
            return questionSentences.length > 0 ? 
                questionSentences.join(' ').trim() : 
                sentences[sentences.length - 1]?.trim() || text;
        }

        return text;
    }
}

// æœ¬åœ° OCR æœåŠ¡
class LocalOCRService extends BaseOCRService {
    getDisplayName() {
        return 'æœ¬åœ°è¯†åˆ«';
    }

    async _performRecognition(image) {
        try {
            const controller = new AbortController();
            const timeoutId = setTimeout(() => controller.abort(), 25000);

            const results = await Promise.all([
                this._recognizeWithParams(image, {
                    tessedit_pageseg_mode: '6',
                    tessedit_ocr_engine_mode: '2',
                    preserve_interword_spaces: '1'
                }, controller.signal),
                this._recognizeWithParams(image, {
                    tessedit_pageseg_mode: '3',
                    tessedit_ocr_engine_mode: '2',
                    preserve_interword_spaces: '0',
                    textord_heavy_nr: '1'
                }, controller.signal)
            ]).finally(() => clearTimeout(timeoutId));

            return this._mergeResults(results);
        } catch (error) {
            if (error.name === 'AbortError') {
                return this._handleTimeout(image);
            }
            throw error;
        }
    }

    async _recognizeWithParams(image, params, signal) {
        try {
            const result = await Tesseract.recognize(
                image,
                'chi_sim+eng',
                {
                    logger: m => {
                        if (m.status === 'recognizing text') {
                            this._updateProgress(Math.floor(m.progress * 100));
                        }
                    },
                    ...params
                }
            );

            if (signal?.aborted) {
                throw new DOMException('Aborted', 'AbortError');
            }

            return result.data.text.trim();
        } catch (error) {
            console.error('OCRè¯†åˆ«å°è¯•å¤±è´¥:', error);
            return '';
        }
    }

    async _handleTimeout(image) {
        this._updateStatus('OCRå¤„ç†è¶…æ—¶ï¼Œå°è¯•ç®€åŒ–å¤„ç†...');
        const result = await Tesseract.recognize(
            image,
            'chi_sim+eng',
            {
                logger: m => {
                    if (m.status === 'recognizing text') {
                        this._updateProgress(Math.floor(m.progress * 100));
                    }
                },
                tessedit_pageseg_mode: '6',
                tessedit_ocr_engine_mode: '2'
            }
        );
        return result.data?.text?.trim() || '';
    }

    _mergeResults(results) {
        const validResults = results.filter(text => text?.length > 0);
        return validResults.length > 0 ? 
            validResults.reduce((a, b) => a.length > b.length ? a : b) : '';
    }

    _updateProgress(percent) {
        window.updateStatus(`OCRè¯†åˆ«: ${percent}%`);
    }

    _updateStatus(status) {
        window.updateStatus(status);
    }
}

// ç™¾åº¦ OCR æœåŠ¡
class BaiduOCRService extends BaseOCRService {
    getDisplayName() {
        return 'ç™¾åº¦äº‘è¯†åˆ«';
    }

    async _performRecognition(image) {
        const imageData = image.replace(/^data:image\/(png|jpg|jpeg);base64,/, '');
        const accessToken = await this._getAccessToken();

        const response = await fetch(`https://aip.baidubce.com/rest/2.0/ocr/v1/accurate_basic?access_token=${accessToken}`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/x-www-form-urlencoded',
                'Accept': 'application/json'
            },
            body: `image=${encodeURIComponent(imageData)}&language_type=CHN_ENG&detect_direction=true&paragraph=true&probability=true`
        });

        if (!response.ok) {
            throw new Error(`ç™¾åº¦OCR APIè¯·æ±‚å¤±è´¥: ${response.status}`);
        }

        const data = await response.json();
        if (data.error_code) {
            throw new Error(`ç™¾åº¦OCRé”™è¯¯: ${data.error_msg} (${data.error_code})`);
        }

        return data.words_result?.map(item => item.words).join('\n') || '';
    }

    async _getAccessToken() {
        const { BAIDU_OCR_API_KEY, BAIDU_OCR_SECRET_KEY } = this.config;
        const url = `https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&client_id=${BAIDU_OCR_API_KEY}&client_secret=${BAIDU_OCR_SECRET_KEY}`;
        
        const response = await fetch(url, { method: 'POST' });
        if (!response.ok) {
            throw new Error('è·å–ç™¾åº¦OCRè®¿é—®ä»¤ç‰Œå¤±è´¥');
        }
        
        const data = await response.json();
        return data.access_token;
    }
}

// OCR æœåŠ¡å·¥å‚
class OCRServiceFactory {
    static create(config) {
        const { OCR_METHOD } = config;
        
        switch (OCR_METHOD.toLowerCase()) {
            case 'local':
                return new LocalOCRService(config);
            case 'baidu':
                return new BaiduOCRService(config);
            default:
                throw new Error(`ä¸æ”¯æŒçš„ OCR æ–¹æ³•: ${OCR_METHOD}`);
        }
    }
}

// å¯¼å‡ºç®€åŒ–ç‰ˆOCRæœåŠ¡
class OCRService {
    constructor(logger) {
        this.service = null;
        this.logger = logger || {
            info: console.log,
            error: console.error,
            warn: console.warn,
            debug: console.log  // æ·»åŠ å…¼å®¹æ€§çš„debugæ–¹æ³•
        };
    }
    
    async recognize(base64Image) {
        // æ£€æŸ¥Tesseractæ˜¯å¦å¯ç”¨
        if (!window.Tesseract) {
            this.logger.warn('Tesseractåº“æœªåŠ è½½ï¼Œä½¿ç”¨æ¨¡æ‹ŸOCR');
            return this._mockRecognize(base64Image);
        }
        
        if (!this.service) {
            this.service = new LocalOCRService({
                MAX_IMAGE_SIZE: 1600,
                IMAGE_QUALITY: 0.8
            });
            
            // ä¿®å¤_updateProgresså’Œ_updateStatusæ–¹æ³•
            this.service._updateProgress = (percent) => {
                if (this.logger && typeof this.logger.info === 'function') {
                    this.logger.info(`OCRè¯†åˆ«: ${percent}%`);
                } else {
                    console.log(`OCRè¯†åˆ«: ${percent}%`);
                }
                
                // å¦‚æœwindow.updateStatuså­˜åœ¨ï¼Œè°ƒç”¨å®ƒ
                if (typeof window.updateStatus === 'function') {
                    window.updateStatus(`OCRè¯†åˆ«: ${percent}%`);
                }
            };
            
            this.service._updateStatus = (status) => {
                if (this.logger && typeof this.logger.info === 'function') {
                    this.logger.info(status);
                } else {
                    console.log(status);
                }
                
                // å¦‚æœwindow.updateStatuså­˜åœ¨ï¼Œè°ƒç”¨å®ƒ
                if (typeof window.updateStatus === 'function') {
                    window.updateStatus(status);
                }
            };
        }
        
        try {
            return await this.service.recognize(base64Image);
        } catch (error) {
            this.logger.error('OCRè¯†åˆ«å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹ŸOCR:', error);
            return this._mockRecognize(base64Image);
        }
    }
    
    // æ¨¡æ‹ŸOCRè¯†åˆ«ï¼Œç”¨äºTesseractä¸å¯ç”¨æ—¶
    _mockRecognize(base64Image) {
        // æ¨¡æ‹ŸOCRå¤„ç†å»¶è¿Ÿ
        return new Promise(resolve => {
            if (typeof window.updateStatus === 'function') {
                window.updateStatus('æ¨¡æ‹ŸOCRè¯†åˆ«ä¸­...');
            }
            
            setTimeout(() => {
                // è¿”å›ä¸€ä¸ªç¤ºä¾‹æ–‡æœ¬
                resolve('è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹é—®é¢˜ã€‚è¯·åœ¨å±å¹•ä¸Šæ˜¾ç¤ºå®é™…éœ€è¦è¯†åˆ«çš„æ–‡å­—ã€‚');
            }, 1000);
        });
    }
}

export { OCRServiceFactory, OCRService }; 