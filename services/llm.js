// åŸºç¡€ LLM æœåŠ¡ç±»
class BaseLLMService {
    constructor(config) {
        if (new.target === BaseLLMService) {
            throw new Error('BaseLLMService ä¸èƒ½ç›´æ¥å®ä¾‹åŒ–');
        }
        this.config = config;
        this.questionCache = new Map();
    }

    async getAnswer(text) {
        if (this.questionCache.has(text)) {
            console.log('ğŸ”„ ä½¿ç”¨ç¼“å­˜çš„å›ç­”');
            return this.questionCache.get(text);
        }

        try {
            const answer = await this._generateAnswer(text);
            this.questionCache.set(text, answer);
            return answer;
        } catch (error) {
            console.error('âŒ LLM APIé”™è¯¯:', error);
            throw error;
        }
    }

    _getSystemPrompt() {
        return `ä½ æ˜¯ä¸“ä¸šè§£é¢˜åŠ©æ‰‹ã€‚è¯·æ³¨æ„ï¼š
1. è¾“å…¥æ–‡æœ¬å¯èƒ½åŒ…å«OCRè¯†åˆ«é”™è¯¯ã€ä¹±ç æˆ–æ— å…³æ–‡å­—ï¼Œè¯·æ™ºèƒ½è¯†åˆ«æ ¸å¿ƒé—®é¢˜å¹¶å¿½ç•¥å¹²æ‰°å†…å®¹
2. å›ç­”æ ¼å¼å¿…é¡»æ˜¯ï¼šã€ç­”æ¡ˆã€‘é€‰é¡¹/ç»“æœ + ç®€çŸ­è§£é‡Š
3. ä¸è¦çŠ¹è±«ï¼Œå¿…é¡»ç»™å‡ºæ˜ç¡®ç­”æ¡ˆ
4. å¦‚æœæ˜¯é€‰æ‹©é¢˜ï¼Œç›´æ¥ç»™å‡ºæ­£ç¡®é€‰é¡¹
5. å¦‚æœæ˜¯é—®ç­”é¢˜ï¼Œç»™å‡ºç®€æ´æ˜ç¡®çš„ç­”æ¡ˆ
6. ä¸è¦è¯´'æˆ‘è®¤ä¸º'æˆ–'å¯èƒ½'ç­‰æ¨¡ç³Šè¡¨è¾¾
7. è‹±æ–‡é—®é¢˜ç”¨è‹±æ–‡å›ç­”ï¼Œæ ¼å¼ä¸ºï¼šã€Answerã€‘option/result + brief explanation`;
    }

    async _generateAnswer(text) {
        throw new Error('_generateAnswer æ–¹æ³•å¿…é¡»ç”±å­ç±»å®ç°');
    }

    async _makeRequest(endpoint, requestBody, apiKey) {
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), 20000);

        try {
            const response = await fetch(endpoint, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Accept': 'application/json',
                    'Authorization': `Bearer ${apiKey}`
                },
                body: JSON.stringify(requestBody),
                signal: controller.signal
            });

            if (!response.ok) {
                const errorText = await response.text();
                throw new Error(`APIè¯·æ±‚å¤±è´¥: ${response.status}, ${errorText}`);
            }

            return await response.json();
        } finally {
            clearTimeout(timeoutId);
        }
    }
}

// SiliconFlow å®ç°
class SiliconFlowService extends BaseLLMService {
    async _generateAnswer(text) {
        const { SILICONFLOW_API_KEY, SILICONFLOW_API_ENDPOINT, SILICONFLOW_MODEL } = this.config;
        
        const requestBody = {
            model: SILICONFLOW_MODEL,
            messages: [
                { role: "system", content: this._getSystemPrompt() },
                { role: "user", content: text }
            ]
        };

        const response = await this._makeRequest(
            SILICONFLOW_API_ENDPOINT,
            requestBody,
            SILICONFLOW_API_KEY
        );

        return response.choices[0].message.content;
    }
}

// DeepSeek å®ç°
class DeepSeekService extends BaseLLMService {
    async _generateAnswer(text) {
        const { DEEPSEEK_API_KEY, DEEPSEEK_API_ENDPOINT } = this.config;
        
        const requestBody = {
            model: "deepseek-chat",
            messages: [
                { role: "system", content: this._getSystemPrompt() },
                { role: "user", content: text }
            ]
        };

        const response = await this._makeRequest(
            DEEPSEEK_API_ENDPOINT,
            requestBody,
            DEEPSEEK_API_KEY
        );

        return response.choices[0].message.content;
    }
}

// LLM æœåŠ¡å·¥å‚
class LLMServiceFactory {
    static create(config) {
        const { LLM_MODEL } = config;
        
        switch (LLM_MODEL.toLowerCase()) {
            case 'siliconflow':
                return new SiliconFlowService(config);
            case 'deepseek':
                return new DeepSeekService(config);
            default:
                throw new Error(`ä¸æ”¯æŒçš„ LLM æ¨¡å‹: ${LLM_MODEL}`);
        }
    }
}

// ç®€åŒ–ç‰ˆLLMæœåŠ¡
class LLMService {
    constructor(logger) {
        this.service = null;
        this.logger = logger || {
            info: console.log,
            error: console.error,
            warn: console.warn,
            debug: console.log  // æ·»åŠ å…¼å®¹æ€§çš„debugæ–¹æ³•
        };
    }
    
    async getAnswer(text) {
        if (!this.service) {
            // åˆ›å»ºä¸€ä¸ªSiliconFlowæœåŠ¡å®ä¾‹
            this.service = new SiliconFlowService({
                SILICONFLOW_API_KEY: 'sk-xslmjbepeyaybceopnrnndvgpicchzmldfsszminyjubkdnk',
                SILICONFLOW_API_ENDPOINT: 'https://api.siliconflow.cn/v1/chat/completions',
                SILICONFLOW_MODEL: 'internlm/internlm2_5-20b-chat'
            });
        }
        
        try {
            return await this.service.getAnswer(text);
        } catch (error) {
            // å¦‚æœå¤±è´¥ï¼Œè¿”å›ä¸€ä¸ªé»˜è®¤å›ç­”
            this.logger.error('LLMæœåŠ¡é”™è¯¯:', error);
            
            return `ã€ç­”æ¡ˆã€‘æ— æ³•è¿æ¥åˆ°è¯­è¨€æ¨¡å‹æœåŠ¡ã€‚è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIé…ç½®ã€‚

é”™è¯¯ä¿¡æ¯: ${error.message || 'æœªçŸ¥é”™è¯¯'}`;
        }
    }
}

export { LLMServiceFactory, LLMService }; 